{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ac14a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7c482a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for mysql connector\n",
    "def mysql_connector():\n",
    "    try:\n",
    "        # Connecting to mysql database using mysql connector\n",
    "        mydb = mysql.connector.connect(host='localhost',user=\"root\",password=\"0007\")\n",
    "        # Creating a cursor for running sql queries\n",
    "        cursor = mydb.cursor()\n",
    "\n",
    "    except Exception as e:\n",
    "        logger(e)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "75a5a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log all the errors in the process\n",
    "import logging as lg\n",
    "def logger(log):\n",
    "    lg.basicConfig(filename='table_create.log',level=lg.ERROR,format=\"%(asctime)s %(name)s %(levelname)s %(message)s\")\n",
    "    lg.error(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e678d0",
   "metadata": {},
   "source": [
    "### Loading and cleaning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "43e99b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load, clean and split data\n",
    "def load_and_clean():\n",
    "    # Loading all the data to a dataframe\n",
    "    data = pd.read_excel(r\"C:\\Users\\mdnis\\Desktop\\NUVENTO\\source_target_field_map.xlsx\")\n",
    "    \n",
    "    # Splitting Source and Target fields to different dataframes\n",
    "    df1 = data[['SourceTableName','SourceColumnName']]\n",
    "    df2 = data[['TargetTableName','TargetColumnName']]\n",
    "    \n",
    "    # Creating a new field which is concatenation of the two fields\n",
    "    df1['SourceColumnName_New'] = df1['SourceTableName'] +\" \"+ df1['SourceColumnName']\n",
    "    df2['TargetColumnName_New'] = df2['TargetTableName'] +\" \"+ df2['TargetColumnName']\n",
    "    \n",
    "    # Droping the unnecessary field\n",
    "    df1.drop('SourceColumnName',axis=1,inplace=True)\n",
    "    df2.drop('TargetColumnName',axis=1,inplace=True)\n",
    "    \n",
    "    # Dropping the null value columns from df2\n",
    "    df2 = df2.dropna()\n",
    "    \n",
    "load_and_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c45bbc",
   "metadata": {},
   "source": [
    "### Working with the dataframe-1 and dataframe-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5f76526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create all the tables with corresponding fields\n",
    "def table_creator(data_frame_name, new_col_name, new_table_name, db_name):\n",
    "    \n",
    "    # Making a list containing all the table names to be created\n",
    "    table_names = data_frame_name[f'{new_table_name}'].unique().tolist()\n",
    "    \n",
    "    # Selecting the database to work with\n",
    "    cursor.execute(f\"USE {db_name};\")\n",
    "    \n",
    "    col_names_lst = []\n",
    "    for i in table_names:\n",
    "        tblnm = i\n",
    "        col_names_lst = []\n",
    "        for j in data_frame_name[f'{new_col_name}']:\n",
    "            if j.split(\" \")[0] == str(tblnm):\n",
    "                col_names_lst.append(j.split(\" \")[1])\n",
    "        col_qry = \" VARCHAR(50),\".join(col_names_lst)\n",
    "        tbl_qry = f\"CREATE TABLE {tblnm} ({col_qry} VARCHAR(50));\"\n",
    "        cursor.execute(f'{tbl_qry}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c7186bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mysql_connector()\n",
    "    table_creator(df1,'SourceColumnName_New','SourceTableName','new_database')\n",
    "except Exception as e:\n",
    "    print(\"Your Error is : \",e)\n",
    "    logger(e)\n",
    "else:\n",
    "    stat = \"Successfully Completed\"\n",
    "    lg.debug(stat)\n",
    "    print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "61c43c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mysql_connector()\n",
    "    table_creator(df2,'TargetColumnName_New','TargetTableName','new_database1')\n",
    "except Exception as e:\n",
    "    print(\"Your Error is : \",e)\n",
    "    logger(e)\n",
    "else:\n",
    "    stat = \"Successfully Completed\"\n",
    "    lg.debug(stat)\n",
    "    print(stat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a008c",
   "metadata": {},
   "source": [
    "### To Insert the data to corresponding table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d76b4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize data to work for the insertion part\n",
    "def ins_clean_data():\n",
    "    data = pd.read_excel(r\"C:\\Users\\mdnis\\Desktop\\NUVENTO\\source_target_field_map.xlsx\")\n",
    "    data['Final'] = data.SourceTableName + \" \" + data.SourceColumnName + \" \" + data.TargetTableName + \" \" + data.TargetColumnName\n",
    "    data.drop(['SourceTableName','SourceColumnName','TargetTableName','TargetColumnName'],axis=1,inplace=True)\n",
    "    data = data['Final'].dropna()\n",
    "\n",
    "try:\n",
    "    ins_clean_data()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5909c58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed Successfuly\n"
     ]
    }
   ],
   "source": [
    "# Creating a function to capture the corresponding tablenames into a list\n",
    "def tbllist_capture():\n",
    "    tbllst_new = []\n",
    "    for i in data:\n",
    "        tbllst = []\n",
    "        tblnm1 = i.split(\" \")[0]\n",
    "        tblnm2 = i.split(\" \")[2]\n",
    "        #print(tblnm1,tblnm2)\n",
    "        if tblnm1 not in tbllst:\n",
    "            tbllst.append(tblnm1)\n",
    "        if tblnm2 not in tbllst:\n",
    "            tbllst.append(tblnm2)\n",
    "        else:\n",
    "            continue\n",
    "        if tbllst not in tbllst_new:\n",
    "            tbllst_new.append(tbllst)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "try:\n",
    "    tbllist_capture()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger(e)\n",
    "else:\n",
    "    print(\"Process completed Successfuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4805ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed Successfuly\n"
     ]
    }
   ],
   "source": [
    "# Creating a function to capture the corresponding column names into a list\n",
    "def collist_capture():   \n",
    "    collst_new = []\n",
    "    for i in tbllst_new:\n",
    "        collst = [[],[]]\n",
    "        for j in data:\n",
    "            if j.split(\" \")[0] == i[0] and j.split(\" \")[2] == i[1]:\n",
    "\n",
    "                if j.split(\" \")[1] not in collst[0]:\n",
    "                    collst[0].append(j.split(\" \")[1])\n",
    "\n",
    "                if j.split(\" \")[3] not in collst[1]:\n",
    "                    collst[1].append(j.split(\" \")[3])\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "        if collst not in collst_new:\n",
    "            collst_new.append(collst)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "            \n",
    "try:\n",
    "    collist_capture()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger(e)\n",
    "else:\n",
    "    print(\"Process completed Successfuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "80edd9a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed Successfuly\n"
     ]
    }
   ],
   "source": [
    "# Function to migrate data from one table to the corresponding table\n",
    "def transfer_data():\n",
    "    for i in range(16):\n",
    "        qry1 = f\"INSERT INTO new_database1.{tbllst_new[i][1]} (\" + (\",\".join(collst_new[i][1]))\n",
    "        qry2 = \") SELECT \" + \",\".join(collst_new[i][0]) + f\" FROM new_database.{tbllst_new[i][0]};\"\n",
    "\n",
    "        final_qry = qry1 + qry2\n",
    "        cursor.execute(final_qry)\n",
    "\n",
    "try:\n",
    "    transfer_data()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger(e)\n",
    "else:\n",
    "    print(\"Process completed Successfuly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4a9cabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task completed successfuly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a464b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
